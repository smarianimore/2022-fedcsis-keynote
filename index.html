<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/html">
  <head>
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
    />

    <title>Adaptive Intersections @ WETICE 2021</title>
    <meta content="Talk 'Individual and collective self-development' given by Stefano Mariani on behalf of Prof. Franco Zambonelli at FedCSIS 2022" name="description">
    <meta content="Stefano Mariani" name="author">

    <meta content="yes" name="apple-mobile-web-app-capable">
    <meta content="black-translucent" name="apple-mobile-web-app-status-bar-style">
    <meta content="width=device-width, initial-scale=1.0" name="viewport">

    <link rel="stylesheet" href="reveal.js/dist/reset.css" />
    <link rel="stylesheet" href="reveal.js/dist/reveal.css" />
    <link rel="stylesheet" href="reveal.js/dist/theme/white.css" id="theme" />

    <!-- Theme used for syntax highlighted code -->
    <link
      rel="stylesheet"
      href="reveal.js/plugin/highlight/monokai.css"
      id="highlight-theme"
    />

    <!-- Printing and PDF exports -->
    <script>
      var link = document.createElement('link');
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
      document.getElementsByTagName('head')[0].appendChild(link);
    </script>
  </head>
  <body>
    <div class="reveal">
      <div class="slides">

        <section data-transition="convex" data-background-image="res/img/FedCSIS-twitter.jpeg" data-background-opacity=0.15 data-background-size="contain">
          <p><small> FedCSIS @ Sofia, 5/9/2022 </small></p>
          <hr>
          <h2> Individual and collective self-development </h2>
          <hr>
          <p> Marco Lippi, <a href="https://smarianimore.github.io">Stefano Mariani</a>, Matteo Martinelli, <strong>Franco Zambonelli</strong> </p>
          <hr>
          <p><small><em> University of Modena and Reggio Emilia </em></small></p>
        </section>

        <section data-transition="convex">
          <section data-transition="slide" data-background-image="res/img/motivation.jpg" data-background-opacity=0.15 data-background-size="contain">
          <!--<section data-transition="convex" data-background-image="res/img/self-dev.jpg" data-background-opacity=0.15 data-background-size="contain">-->
            <h3> Motivation</h3>
            <hr>
            <ul>
              <li> complexity and unpredictability of deployment scenarios </li>
              <li> need <strong>learn</strong> how to act and adapt with <em>little or no a priori knowledge</em> </li>
              <li> at the individual and collective level </li>
            </ul>
          </section>
          <section data-transition="slide" data-background-image="res/img/goal.jpg" data-background-opacity=0.15 data-background-size="contain">
            <!--<section data-transition="convex" data-background-image="res/img/self-dev.jpg" data-background-opacity=0.15 data-background-size="contain">-->
            <h3> Goal</h3>
            <hr>
            <p> <em>become able to autonomously (i.e., <strong>self-) develop models</strong> of themselves and the environment (including others)</em> </p>
          </section>

        <!--<section data-transition="convex" data-background-image="res/img/toddler.jpg" data-background-opacity=0.15 data-background-size="contain">-->
          <section data-transition="slide" data-background-image="res/img/self-dev.jpg" data-background-opacity=0.15 data-background-size="contain">
            <h3> On self-development </h3>
            <hr>
            <ul>
              <li> toddlers touch (lick ðŸ˜…) objects, interact with people, etc. </li>
              <li> you click buttons, try actions, and explore objects when starting a new videogame </li>
            </ul>
            <p> <em>this is part of a <strong>self-development</strong> (aka autonomous mental dev) <strong>process</strong> to acquire and improve cognitive and behavioural capabilities</em> </p>
          </section>
          <section data-transition="slide" data-background-image="res/img/self-dev.jpg" data-background-opacity=0.15 data-background-size="contain">
            <ul>
              <li> recognize situations </li>
              <li> the sense of self </li>
              <li> the <strong>sense of agency</strong> (i.e., understanding effect of own actions) </li>
              <li> act purposefully towards a goal </li>
              <li> cooperate/compete with others </li>
            </ul>
            <hr>
          </section>
          <section data-transition="slide" data-background-image="res/img/matrix.jpg" data-background-opacity=0.15 data-background-size="contain">
            <h3> In ICT </h3>
            <hr>
            <p> for small-scale, static, and/or simple scenarios/tasks it is possible "hardwire" a model </p>
            <p> otherwise software has to: </p>
            <ul>
              <li> build models and update them </li>
              <li> recognise effect of own actions in (novel) context </li>
              <li> learn to achieve goals in (novel) context </li>
              <li> learn to cooperate/compete with others </li>
            </ul>
            <p> <em>that is, to <strong>self-develop</strong> :)</em> </p>
          </section>
        </section>

        <section data-transition="convex" data-background-image="res/img/contribution.jpg" data-background-opacity=0.15 data-background-size="contain">
          <section data-transition="slide">
            <h3> Contribution </h3>
            <hr>
            <ul>
              <li> conceptual framework of self-development in ICT systems </li>
              <li> suitable application domains </li>
              <li> research areas as building blocks </li>
              <li> promising early results </li>
              <li> key research challenges </li>
            </ul>
          </section>
        </section>

        <section data-transition="convex"> <!--data-background-image="res/img/contribution.jpg" data-background-opacity=0.15 data-background-size="contain">-->
          <section data-transition="slide">
            <h3> Conceptual framework </h3>
            <hr>
            <img width="125%" height="125%" data-src="res/img/framework.png">

                  <!--<li> through embodiment and perception an agent tries to interact... </li>
                  <li> ...to learn the effect of own actions so as to acquire the sense of agency </li>
                  <li> then it can start behaving in a goal-oriented way </li>
                  <li> the agent also learns to recognize the self and
                    non-self... </li>
                  <li> ...so as to develop strategic thinking (i.e. take into account others' actions)... </li>
                  <li> ...and understand whether it can communicate with others... </li>
                  <li> ...to either cooperate or compete </li>
                  <li> such coordination knowledge may then become institutionalized for others to adopt </li>-->

          </section>
          <section data-transition="slide" data-background-image="res/img/individual.jpg" data-background-opacity=0.15 data-background-size="contain">
            <h3> Individual level </h3>
            <hr>
            <ul>
              <li> <strong>embodiment</strong> and <strong>perception</strong>: recognize available observations $O$ and actions $A$, i.e. get acknowledged of its
                actuating and sensing skills, and their relationships </li>
              <li> <strong>sense of agency</strong>: understand the (causal) effects of $A$ on $O$ </li>
              <li> <strong>goal-orientedness</strong>: learn the required sequence of $a_i \in A$ to achieve a specific goal $g$ </li>
            </ul>
          </section>
          <section data-transition="slide" data-background-image="res/img/boundary.png" data-background-opacity=0.15 data-background-size="contain">
            <h3> Individual-Collective boundary </h3>
            <hr>
            <ul>
              <li> <strong>self/non-self</strong>: become aware of other agents $J$ affecting $O$ </li>
              <li> <strong>strategic thinking</strong>: understand effects of $J$ on $O$ and exploit them for own $g$ </li>
            </ul>
          </section>
          <section data-transition="slide" data-background-image="res/img/collective.png" data-background-opacity=0.15 data-background-size="contain">
            <h3> Collective level </h3>
            <hr>
            <ul>
              <li> <strong>communication</strong>: understand how/when to send and receive which messages $M$, as a form of social action/perception </li>
              <li> <strong>coordination</strong>: recognize how $M$ affect $J$ and in turn $O$, as a form of social sense of agency </li>
              <li> <strong>institution</strong>: learn which sequence of $m_i \in M$ to which $j_i \in J$ achieves collective goal $g$ </li>
            </ul>
          </section>
        </section>

        <section data-transition="convex">
          <section data-transition="slide" data-background-image="res/img/applications.jpg" data-background-opacity=0.15 data-background-size="contain">
            <h3> Application domains </h3>

          </section>
          <section data-transition="slide" data-background-image="res/img/robotics.jpg" data-background-opacity=0.15 data-background-size="contain">
            <h3> Robotics </h3>
            <hr>
            <ul>
              <li> robots with some nuance of individual self-dev are already a thing </li>
              <small><ul>
                <li> e.g. Simultaneous Location and Mapping (SLAM) </li>
                <li> e.g. estimate residual capabilities after fault or damage </li>
              </ul></small>
              <li> the collective level is less established but growing (swarm robotics [1]) </li>
            </ul>
            <p style="color:grey"><small><small><em> [1] N. Cambier et al.: "Language evolution in swarm robotics: A perspective" Frontiers in Robotics and AI, vol. 7, p. 12, 2020 </em></small></small></p>
          </section>
          <section data-transition="slide" data-background-image="res/img/smart-building.jpg" data-background-opacity=0.15 data-background-size="contain">
            <h3> Smart buildings </h3>
            <hr>
            <p> who is still dreaming of a truly smart home/office/building? ðŸ™‹ [2] </p>
            <small><ul>
              <li> saying "I'm tired" when coming home $\rightarrow$ lights down, lounge music plays, tha bathtube starts filling </li>
              <li> saying "lab meeting in 5 mins" in a meeting room $\rightarrow$ widescreen turns on, as lights do, and the coffee machine warms up </li>
              <li> all with zero configuration? </li>
            </ul></small>
            <p> devices become truly smart when they learn a model of environment to exploit for goals [3,4] </p>
            <p style="color:grey"><small><small><em> [2] F. Zambonelli et al.: "Coordinating Distributed Speaking Objects" ICDCS 2017: 1949-1960 <br>
              [3] F. Zambonelli et al.: "Developing a sense of agency in IoT systems: Preliminary experiments in a smart home scenario" 17th CoMoRea workshop at PerCom. IEEE, 2021 <br>
              [4] K. Fadiga et al.: "To do or not to do: finding causal relations in smart homes" ACSOS 2021: 110-119
            </em></small></small></p>
          </section>
          <section data-transition="slide" data-background-image="res/img/smart-factory.jpg" data-background-opacity=0.15 data-background-size="contain">
            <h3> Smart factories </h3>
            <hr>
            <p> adaptability and flexibility are key concerns for industry 4.0 [5] </p>
            <ul>
              <li> self-configuration when re-deploying machinery in new environment </li>
              <li> re-planning production line after fault or if new equipment joins </li>
            </ul>
            <p> high-fidelity simulation (Digital Twins?) mandatory to learn in a safe environment! </p>
            <p style="color:grey"><small><small><em> [5] J. Zhang et al.: "Self-organizing manufacturing: Current status and prospect for industry 4.0" 5th International Conference on Enterprise Systems, 2017, pp. 319â€“326 </em></small></small></p>
          </section>
          <section data-transition="slide" data-background-image="res/img/smart-ciy.jpg" data-background-opacity=0.15 data-background-size="contain">
            <h3> Smart cities </h3>
            <hr>
            <ul>
              <li> natural scale-up from buildings and factories, similar issues </li>
              <li> many scenarios </li>
              <small><ul>
                <li> smart mobility </li>
                <li> smart energy grids </li>
                <li> cooperative driving [6] </li>
                <li> ... </li>
              </ul></small>
              <li> learning in a simulated environment even more critical to avoid damage! </li>
            </ul>
            <p style="color:grey"><small><small><em> [6] F. Zambonelli et al.: "An Adaptive Approach for the Coordination of Autonomous Vehicles at Intersections" WETICE 2021: 1-6 </em></small></small></p>
          </section>
        </section>

        <section data-transition="convex">
          <section data-transition="slide">
            <h3> Building blocks </h3>
            <hr>
            <img width="100%" height="100%" data-src="res/img/research-landscape.png">
          </section>
          <section data-transition="slide">
            <p> We take for granted the <strong>basics</strong> of individual self-development,
              i.e., <em>perception and embodiment</em>,
              as tools already exist to give software agents
              sophisticated <strong>sensing and actuation</strong> capabilities
              (e.g., CNNs to recognize objects, scenes, etc.)</p>
            <hr>
          </section>
        </section>

        <section data-transition="convex" data-background-image="res/img/goal-orientedness.jpg" data-background-opacity=0.15 data-background-size="contain">
          <section data-transition="slide">
            <h3> Goal-orientedness </h3>
            <hr>
            <p> <strong>RL</strong> and <strong>MARL</strong> are making huge headlines
              and roughly resemble the whole idea of self-dev </p>
            <p> ...but rarely build <span class="fragment highlight-red">explicit (causal?) models</span> of the world
              hence are limited in </p>
            <small><ul>
              <li> learning in highly non-stationary envs </li>
              <li> multi-task learning </li>
              <li> cross-domain learning </li>
              <li> transfer learning </li>
              <li> generalisation power </li>
            </ul></small>
          </section>
          <section data-transition="slide">
            <p> <strong>curriculum learning</strong> better resembles the self-dev process </p>
            <ul>
              <li> the agent is first trained on simple tasks </li>
              <li> learnt expertise is exploited in increasingly complex tasks/scenarios </li>
              <li> "higher" skills are learnt exploiting "lower" skills, not from scratch </li>
              <li> still mostly not building explicit models </li>
            </ul>
          </section>
          <section data-transition="slide">
            <p> research on <strong>intrinsic motivations</strong> is similar, too </p>
            <ul>
              <li> extrinsic motivations (most of RL) are designed by an "oracle" (the scientist) </li>
              <li> intrinsic motivations are made up by agents themselves </li>
              <li> agents thus learn (at first) out of exploration and curiosity </li>
            </ul>
            <hr>
          </section>
        </section>

        <section data-transition="convex" data-background-image="res/img/causality.png" data-background-opacity=0.15 data-background-size="contain">
          <section data-transition="slide">
            <h3> Causal models </h3>
            <hr>
            <p> Understanding and leveraging (the ladder of) <strong>causality</strong> is recognized as a key for <strong>general AI</strong> </p>
            <ul>
              <li> <em>association</em>: not yet causation, but correlation </li>
              <li> <em>intervention</em>: tell causes apart from effects (e.g. predict consequences of actions) </li>
              <li> <em>counterfactual</em>: reasoning on alternative realities (e.g. "what-if" analysis)</li>
            </ul>
          </section>
          <section data-transition="slide">
            <ul>
              <li> association $\leftrightarrow$ embodiment and perception </li>
              <li> intervention $\leftrightarrow$ sense of agency, self and non-self </li>
              <li> counterfactual $\leftrightarrow$ goal-orientedness, strategic thinking, coordination </li>
            </ul>
            <p> <em>most of mainstream machine learning research doesn't go beyond the level of association!</em> [7,8] </p>
            <p style="color:grey"><small><small><em> [7] J. Pearl: "The seven tools of causal inference, with reflections on machine learning" CACM 62(3): 54-60 (2019) <br>
              [8] B. SchÃ¶lkopf et al.: "Toward Causal Representation Learning" Proceedings IEEE 109(5): 612-634 (2021) </em></small></small></p>
          </section>
        </section>

        <section data-transition="convex" data-background-image="res/img/autocurricula.png" data-background-opacity=0.15 data-background-size="contain">
          <section data-transition="slide">
            <h3> Autocurricula </h3>
            <hr>
            <ul>
              <li> multi-agent learning setting, social interactions </li>
              <li> the more one agent learns, the more it challenges others </li>
              <li> continuous increase in learning task complexity </li>
              <li> incremental (curriculum) learning triggered by social interactions (<em>auto</em>)</li>
            </ul>
          </section>
        </section>

          <section data-transition="slide">
            <h3> Selected approaches </h3>
            <hr>
            <ul>
              <li> precedence-based <strong>right of way</strong> as baseline </li>
              <div class="fragment">
                <li> centralised <strong>reservation-based</strong> as "best in class" </li>
                <small><ul>
                  <li> IM receives space-time reservations for intersection cells from approaching vehicles </li>
                  <li> IM elaborates collision-free trajectories </li>
                  <li> IM communicates back to vehicles their parameters for crossing (e.g. speed profile) </li>
                </ul></small>
              </div>
              <div class="fragment">
                <li> decentralised <strong>competitive auction</strong> as state-of-art </li>
                <small><ul>
                  <li> vehicles bid for space-time slots within the intersection </li>
                  <li> non-colliding vehicles cross simultaneously </li>
                  <li> a broker collects bids and ranks them to assign the right of way </li>
                </ul></small>
              </div>
            </ul>
          </section>
        </section>

        <section data-transition="convex" data-background-image="sumo.png" data-background-opacity=0.10 data-background-size="cover">
          <section data-transition="slide">
            <h3> Performance comparison </h3>
            <hr>
            <ul>
              <li> SUMO simulations, controlled via TraCi API (<a href="https://www.eclipse.org/sumo/">www.eclipse.org/sumo/</a>) </li>
              <li> <strong>reservation</strong> based on temporal allocations of the intersection area, divided into a grid of occupancy cells [1] </li>
              <li> <strong>English auctions</strong> with virtual wallets [2] </li>
            </ul>
            <hr>
            <p style="color:grey"><small><em> [1] Kurt M. Dresner, Peter Stone: A Multiagent Approach to Autonomous Intersection Management. J. Artif. Intell. Res. 31: 591-656 (2008) </em></small></p>
            <p style="color:grey"><small><em> [2] Dustin Carlino, Stephen D. Boyles, Peter Stone: Auction-based autonomous intersection management. ITSC 2013: 529-534 </em></small></p>
          </section>
          <section data-transition="slide">
            <h3> Simulation settings </h3>
            <hr>
            <style>
              .container{
                display: flex;
              }
              .col{
                flex: 1;
              }
            </style>
            <div class="container">
              <div class="col">
                <img width="512" height="384" align="left" data-src="junction.png">
              </div>
              <div class="col">
                <ul>
                  <li> single 4-ways junction </li>
                  <li> 3 lanes for each way </li>
                  <li> 1 to 4 vehicles/second (traffic condition) </li>
                  <li> 33/66 % of left turning </li>
                  <li> 30 runs for each params combination </li>
                </ul>
              </div>
            </div>
          </section>
          <section data-transition="slide">
            <h3> Results </h3>
            <hr>
            <style>
              .container{
                display: flex;
              }
              .col{
                flex: 1;
              }
            </style>
            <div class="container">
              <div class="col">
                <img width="512" height="384" align="left" data-src="throughput_24-05-2021.png">
              </div>
              <div class="col">
                <img width="512" height="384" align="left" data-src="st_dev_head_time_24-05-2021.png">
              </div>
            </div>
            <ul>
              <li class="fragment"> no approach works best across traffic conditions </li>
              <li class="fragment"> no approach works best across performance metrics </li>
            </ul>
          </section>
        </section>

        <section data-transition="convex" data-background-image="adaptation.jpg" data-background-opacity=0.25 data-background-size="cover">
          <section data-transition="slide">
            <h3> Adaptive approach </h3>
            <hr>
            <ul>
              <li class="fragment"> <strong>learn</strong> which approach works best in which traffic condition </li>
              <li class="fragment"> <strong>apply</strong> the best approach known upon changing conditions </li>
              <li class="fragment"> both with respect to a <em>target performance metric</em> </li>
            </ul>
            <hr>
            <p class="fragment">
              <small><em>municipalities already do this!<br>(e.g. traffic lights turned off at night)</em></small>
            </p>
          </section>
          <section data-transition="slide">
            <h3> Adaptive Intersection Manager (AIM) </h3>
            <hr>
            <ol>
              <div class="fragment">
                <li> learning phase (naive <em>Q-learning</em>*): </li>
                <small><ol>
                  <li> randomly select coordination approach $A$ </li>
                  <li> apply $A$ for a given time $T$ </li>
                  <li> monitor both traffic conditions $C$ and target performance metric $M$ during $T$ </li>
                </ol></small>
              </div>
              <div class="fragment">
                <li> adaptation phase: </li>
                <small><ol>
                  <li> sample traffic condition $C$ </li>
                  <li> lookup best approach $A$ for $C$ regarding $M$ </li>
                  <li> apply $A$ until $C \rightarrow C'$ </li>
                  <li> loop </li>
                </ol></small>
              </div>
            </ol>
            <hr>
            <p class="fragment"><small><em> * action = application of $a \in A$ during $T$, reward = $M$ measured during $T$ </em></small></p>
          </section>
          <section data-transition="slide">
            <h3> Results </h3>
            <hr>
            <style>
              .container{
                display: flex;
              }
              .col{
                flex: 1;
              }
            </style>
            <div class="container">
              <div class="col">
                <img width="512" height="384" align="left" data-src="th_training_th2.png">
              </div>
              <div class="col">
                <img width="512" height="384" align="left" data-src="sv_training_sv2.png">
              </div>
            </div>
            <ul>
              <li class="fragment"> the AIM <em>pursues</em> the best $A$ known for every $C$ </li>
              <li class="fragment"> the AIM accounts for the target $M$ to optimise </li>
            </ul>
          </section>
        </section>

        <section data-transition="convex" data-background-image="dead-end.jpg" data-background-opacity=0.15 data-background-size="cover">
          <h3> Conclusion & outlook </h3>
          <hr>
          <style>
            .container{
              display: flex;
            }
            .col{
              flex: 1;
            }
          </style>
          <div class="container">
            <div class="col fragment">
              <ul>
                <li> adaptive approach to intersection crossing presented </li>
                <li> simulations validate approach empirically </li>
                <li> promising results despite simplicity </li>
              </ul>
            </div>
            <div class="col fragment">
              <ul>
                <li> extend to more complex measure of $C$ </li>
                <li> extend to more $m \in M$ at once </li>
                <li> extend to more sophisticated learning </li>
              </ul>
            </div>
          </div>
        </section>

        <section data-transition="convex" data-background-image="confused-meme.png" data-background-opacity=0.25 data-background-size="cover">
          <h3> Thanks </h3>
          <h3> for your attention </h3>
          <hr>
          <p><a href="https://smarianimore.github.io"> Stefano Mariani </a></p>
          <hr>
          <p><em> UniversitÃ  di Modena e Reggio Emilia </em></p>
        </section>

      </div>
    </div>

    <script src="reveal.js/dist/reveal.js"></script>
    <script src="reveal.js/plugin/notes/notes.js"></script>
    <script src="reveal.js/plugin/markdown/markdown.js"></script>
    <script src="reveal.js/plugin/highlight/highlight.js"></script>
    <script src="reveal.js/plugin/zoom/zoom.js"></script>
    <script src="reveal.js/plugin/math/math.js"></script>
    <script>
      // More info about initialization & config:
      // - https://revealjs.com/initialization/
      // - https://revealjs.com/config/
      Reveal.initialize({
        hash: true,
        progress: true,
        //autoSlide: 3000,
        pdfSeparateFragments: false,
        // Learn about plugins: https://revealjs.com/plugins/
        plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealZoom, RevealMath],
      });
    </script>
  </body>
</html>
